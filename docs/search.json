[
  {
    "objectID": "posts/ice/index.html",
    "href": "posts/ice/index.html",
    "title": "Cold as ICE",
    "section": "",
    "text": "ICE data\nRecently I managed to understand the way the (unofficial) API of the Intercontinental exchange works, giving access to very interesting futures data. This way we can make some interesting analysis - lets start by simply calculating dark, spark spreads.\n\n\nCode\nlibrary(tidyverse)\nlibrary(ospowertrader)\n\n# get the data\nproducts <- list(\n  api2_coal = list(\n    productId = 517,\n    hubId     = 681,\n    desc = \"api2\"\n  ),\n  ttf_gas = list(\n    productId = 4331,\n    hubId     = 7979,\n    desc = \"ttf\"\n  ),\n  brent_crude = list(\n    productId = 254,\n    hubId     = 403,\n    desc = \"brent\"\n  ),\n  german_power = list(\n    productId = 19032,\n    hubId     = 21971,\n    desc = \"german_power_base\"\n  ),\n  eua = list(\n    productId = 390,\n    hubId     = 564,\n    desc = \"eua\"\n  )\n)\n\ndf <- tibble(products) %>% \n  unnest_wider(products)\n\n\ndf <- df %>% \n  mutate(data = map2(.x = productId, .y = hubId, ~ice_futures_list(productId = .x, hubId = .y))) %>% \n  unnest(data)\n\n\nprice_table <- df %>%\n  select(desc, marketStrip, lastPrice) %>% \n  pivot_wider(names_from = desc, values_from = lastPrice)\n\nknitr::kable(price_table)\n\n\n\n\n\nmarketStrip\napi2\nttf\nbrent\ngerman_power_base\neua\n\n\n\n\nDec23\n123.00\nNA\nNA\nNA\n68.62\n\n\nJan24\n118.25\n38.840\nNA\n94.32\n69.35\n\n\nFeb24\n113.75\n39.345\n75.65\n101.61\nNA\n\n\nQ1 24\n114.00\n39.205\nNA\n95.48\nNA\n\n\nMar24\n110.50\n39.290\n75.80\n90.89\n69.40\n\n\nApr24\n110.50\n38.860\n75.82\nNA\nNA\n\n\nMay24\nNA\n38.410\n75.80\nNA\nNA\n\n\nQ2 24\n110.50\n38.695\nNA\nNA\nNA\n\n\nJun24\nNA\n38.595\n75.73\nNA\nNA\n\n\nJul24\nNA\n38.590\n75.63\nNA\nNA\n\n\nAug24\nNA\n38.610\n75.47\nNA\nNA\n\n\nQ3 24\n112.00\n38.670\nNA\nNA\nNA\n\n\nSep24\nNA\n38.890\n75.27\nNA\nNA\n\n\nOct24\nNA\n39.715\n75.37\nNA\nNA\n\n\nNov24\nNA\n42.640\n75.13\nNA\nNA\n\n\nCal 24\n112.15\n39.500\nNA\nNA\nNA\n\n\nQ4 24\n114.00\n42.285\nNA\n112.37\nNA\n\n\nDec24\nNA\n44.270\n74.60\nNA\n71.61\n\n\nSummer24\nNA\n38.650\nNA\nNA\nNA\n\n\nJan25\nNA\n44.275\n74.64\nNA\nNA\n\n\nFeb25\nNA\n43.500\n73.94\nNA\nNA\n\n\nWinter24\nNA\n43.035\nNA\nNA\nNA\n\n\nQ1 25\nNA\n43.800\nNA\nNA\nNA\n\n\nMar25\nNA\nNA\nNA\nNA\n72.61\n\n\nApr25\nNA\nNA\nNA\nNA\nNA\n\n\nMay25\nNA\n37.375\nNA\nNA\nNA\n\n\nQ2 25\nNA\n37.800\nNA\nNA\nNA\n\n\nJun25\nNA\n37.350\n73.22\nNA\nNA\n\n\nJul25\nNA\nNA\nNA\nNA\nNA\n\n\nAug25\nNA\nNA\nNA\nNA\nNA\n\n\nSummer25\nNA\n37.360\nNA\nNA\nNA\n\n\nQ3 25\nNA\n36.810\nNA\nNA\nNA\n\n\nSep25\nNA\nNA\nNA\nNA\nNA\n\n\nOct25\nNA\nNA\nNA\nNA\nNA\n\n\nNov25\nNA\nNA\nNA\nNA\nNA\n\n\nCal 25\nNA\n39.300\nNA\n98.88\nNA\n\n\nQ4 25\nNA\n38.800\nNA\nNA\nNA\n\n\nDec25\nNA\nNA\n72.06\nNA\n74.41\n\n\nJan26\nNA\nNA\nNA\nNA\nNA\n\n\nFeb26\nNA\nNA\nNA\nNA\nNA\n\n\nWinter25\nNA\n39.100\nNA\nNA\nNA\n\n\nQ1 26\nNA\nNA\nNA\nNA\nNA\n\n\nMar26\nNA\nNA\nNA\nNA\n75.46\n\n\nApr26\nNA\nNA\nNA\nNA\nNA\n\n\nMay26\nNA\nNA\nNA\nNA\nNA\n\n\nJun26\nNA\nNA\n71.10\nNA\nNA\n\n\nJul26\nNA\nNA\nNA\nNA\nNA\n\n\nAug26\nNA\nNA\nNA\nNA\nNA\n\n\nSummer26\nNA\n32.450\nNA\nNA\nNA\n\n\nSep26\nNA\nNA\nNA\nNA\nNA\n\n\nOct26\nNA\nNA\nNA\nNA\nNA\n\n\nNov26\nNA\nNA\nNA\nNA\nNA\n\n\nCal 26\nNA\n34.500\nNA\nNA\nNA\n\n\nDec26\nNA\nNA\n70.22\nNA\n77.25\n\n\nJan27\nNA\nNA\nNA\nNA\nNA\n\n\nFeb27\nNA\nNA\nNA\nNA\nNA\n\n\nWinter26\nNA\n34.400\nNA\nNA\nNA\n\n\nMar27\nNA\nNA\nNA\nNA\nNA\n\n\nJun27\nNA\nNA\nNA\nNA\nNA\n\n\nDec27\nNA\nNA\n69.65\nNA\nNA\n\n\nDec28\nNA\nNA\nNA\nNA\nNA\n\n\n\n\n\nSo we can see there are different market strips to consider. Unfortunately we cannot determine the value for all spreads, since not all last prices are published for each product.\n\nConversion table:\n\nAssumptions:\n\ncoal plant:\n\n1 MWh of thermal energy in 0.1228 tonnes of coal\ncoal plant efficiency is 37 %\nwith a CO2 output of 0.34 tonnes\n\nsingle cycle gas:\n\n40% efficiency\n0.2 tonnes of CO2 output\n\ncombined cycle (ccgt):\n\n60% efficiency\nwith 0.2 tonnes of CO2 output\n\n\n\n\nCode\nspread <- function(fuel_cost, efficiency, power){\n  spark_spread <- power - (fuel_cost/efficiency)\n  # spred         # revenue # cost\n  return(spark_spread)\n}\n\nclean_spread <- function(fuel_cost, efficiency, power, co2_mwh, co2_price){\n  clean_spread <- power - ((fuel_cost / efficiency) + co2_mwh * co2_price)\n  return(clean_spread)\n}\n\nprice_table %>% \n  mutate(\n    spark = spread(ttf, 0.40, german_power_base),\n    dark  = spread(api2 * 0.1228, 0.37, german_power_base),\n    spark_ccgt = spread(ttf, 0.6, german_power_base),\n    clean_spark = clean_spread(ttf, 0.40, german_power_base, 0.2, eua),\n    clean_dark = clean_spread(api2 * 0.1228, 0.37, german_power_base, 0.34, eua),\n    clean_spark_ccgt = clean_spread(ttf, 0.6, german_power_base, 0.2, eua)\n    ) %>% \n  filter(!is.na(german_power_base)) %>% \n  mutate(across(where(is.numeric), ~round(., digits = 2))) %>% \n  knitr::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmarketStrip\napi2\nttf\nbrent\ngerman_power_base\neua\nspark\ndark\nspark_ccgt\nclean_spark\nclean_dark\nclean_spark_ccgt\n\n\n\n\nJan24\n118.25\n38.84\nNA\n94.32\n69.35\n-2.78\n55.07\n29.59\n-16.65\n31.49\n15.72\n\n\nFeb24\n113.75\n39.34\n75.65\n101.61\nNA\n3.25\n63.86\n36.03\nNA\nNA\nNA\n\n\nQ1 24\n114.00\n39.20\nNA\n95.48\nNA\n-2.53\n57.64\n30.14\nNA\nNA\nNA\n\n\nMar24\n110.50\n39.29\n75.80\n90.89\n69.40\n-7.33\n54.22\n25.41\n-21.21\n30.62\n11.53\n\n\nQ4 24\n114.00\n42.28\nNA\n112.37\nNA\n6.66\n74.53\n41.90\nNA\nNA\nNA\n\n\nCal 25\nNA\n39.30\nNA\n98.88\nNA\n0.63\nNA\n33.38\nNA\nNA\nNA\n\n\n\n\n\n\n\nCode\nmarket_strips <- price_table %>% \n  filter(!is.na(german_power_base)) %>%\n  pull(marketStrip)\n\n\nmarket_strips[1]\n\n\n[1] \"Jan24\"\n\n\nMarket strip we want to analyse historical data for.\nUnfortunately EUA is missing for a long period of time, so I will use the first present value to interpolate the series. This will only move spark and dark downwards.\nWhat is very interesting are the spreads during August 2022. There seems to be a moment where spark spreads become highly profitable for a short period of time. Up to the 23rd of August we see that spark spread move slightly over zero, suddenly they spike for the Jan24 marketStrip. Also interesting is how profitable dark spreads seem to be (of course the parameters we used estimating the efficiency play a role or the quality of the coal in general, maybe 0.1228 tons for a thermal MWh is too optimistic)\n\n\nCode\nhistorical_data <- df %>% \n  filter(marketStrip == market_strips[1]) %>% \n  mutate(price_data = map(marketId, ~ice_historical_data(marketId = .x, span = 3)))\n\nhistorical_data %>% \n  unnest(price_data) %>% \n  select(desc, date, price) %>% \n  pivot_wider(names_from = desc, values_from = price) %>%\n  fill(eua, .direction = \"downup\") %>% \n  mutate(\n    spark = spread(ttf, 0.40, german_power_base),\n    dark  = spread(api2 * 0.1228, 0.37, german_power_base),\n    spark_ccgt = spread(ttf, 0.6, german_power_base),\n    clean_spark = clean_spread(ttf, 0.40, german_power_base, 0.2, eua),\n    clean_dark = clean_spread(api2 * 0.1228, 0.37, german_power_base, 0.34, eua),\n    clean_spark_ccgt = clean_spread(ttf, 0.6, german_power_base, 0.2, eua)\n    ) %>% \n  filter(!is.na(german_power_base)) %>% \n  select(date, spark, spark_ccgt, dark, starts_with(\"clean\")) %>% \n  pivot_longer(-date) %>% \n  timetk::plot_time_series(date, value, name, .smooth = FALSE, .y_intercept = 0, .title = market_strips[1])\n\n\n\n\n\n\nPlot just the input prices:\n\n\nCode\nhistorical_data %>% \n  unnest(price_data) %>% \n  select(date, desc, price) %>% \n  timetk::plot_time_series(\n    date, price, desc, .smooth = FALSE, .title = market_strips[1]\n  )\n\n\n\n\n\n\n\n\nCode\n## define a function\n\nplot_spreads <- function(market_strip){\n  \n  historical_data <- df %>% \n  filter(marketStrip == market_strips[market_strip]) %>% \n  mutate(price_data = map(marketId, ~ice_historical_data(marketId = .x, span = 3)))\n\nhistorical_data %>% \n  unnest(price_data) %>% \n  select(desc, date, price) %>% \n  pivot_wider(names_from = desc, values_from = price) %>%\n  #fill(eua, .direction = \"downup\") %>% \n  mutate(\n    spark = spread(ttf, 0.40, german_power_base),\n    dark  = spread(api2 * 0.1228, 0.37, german_power_base),\n    spark_ccgt = spread(ttf, 0.6, german_power_base),\n    clean_spark = clean_spread(ttf, 0.40, german_power_base, 0.2, eua),\n    clean_dark = clean_spread(api2 * 0.1228, 0.37, german_power_base, 0.34, eua),\n    clean_spark_ccgt = clean_spread(ttf, 0.6, german_power_base, 0.2, eua)\n    ) %>% \n  filter(!is.na(german_power_base)) %>% \n  select(date, spark, spark_ccgt, dark, starts_with(\"clean\")) %>% \n  pivot_longer(-date) %>% \n  timetk::plot_time_series(date, value, name, .smooth = FALSE, .y_intercept = 0, .title = market_strips[market_strip])\n\n}\n\n\nLet’s also analyse the future prices for March 24. For other strips there are no EUA prices.\nInterestingly there is a more complete EUA price curve. It is very interesting to see how much the EUA component takes out of the profit margins of a Gas or Coal Power plant.\n\n\nCode\n# run for second strip\nplot_spreads(4)"
  },
  {
    "objectID": "posts/out_of_balance/index.html",
    "href": "posts/out_of_balance/index.html",
    "title": "Out of balance",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(ospowertrader)\nlibrary(lubridate)\nlibrary(timetk)\nlibrary(arrow)"
  },
  {
    "objectID": "posts/out_of_balance/index.html#exploring-the-link-between-imbalance-prices-in-the-apg-control-area-and-terna",
    "href": "posts/out_of_balance/index.html#exploring-the-link-between-imbalance-prices-in-the-apg-control-area-and-terna",
    "title": "Out of balance",
    "section": "Exploring the link between imbalance prices in the APG control area and Terna",
    "text": "Exploring the link between imbalance prices in the APG control area and Terna\n\n\nCode\napg_prices <- arrow::read_parquet(\"./data/apg_imbalance_prices.parquet\")\nterna_prices <- arrow::read_parquet(\"./data/terna_imbalance_prices.parquet\")\n\ncombined_prices <- apg_prices %>% \n  inner_join(terna_prices, by = c(\"df\" = \"reference_date\")) %>% \n  select(df, apg_price = ae_price, terna_price = unbalance_price_EURxMWh) \n\ncombined_prices %>% \n  pivot_longer(-df) %>% \n  timetk::plot_time_series(\n    df, value, name, .smooth = FALSE, .title = \"APG vs Terna (1)\"\n  )\n\n\n\n\n\n\nThis graph shows pretty well the impact of Terna’s participation to the Picasso platform. While large spikes, which were already common in the Austrian Control Area, were unheard of in Italy, after the 19th of July they became relatively common in Italy too.\n\n\nCode\ncombined_prices %>% \n  ggplot(aes(apg_price, terna_price))+\n  stat_binhex(bins = 50)+\n  scale_fill_gradient(low = \"blue\", high = \"red\")+\n  theme_bw()+\n  ggtitle(\"APG vs Terna (2)\")\n\n\n\n\n\nHere we can see there is a lot of covariance for extreme values, notice (!) the difference in scale. APG tends to present much extremer imbalance prices.\n\n\nCode\ncombined_prices %>% \n  filter(abs(apg_price) < 300 & abs(terna_price) < 300) %>% \n  ggplot()+\n  geom_histogram(aes(apg_price), alpha = 0.8, fill = \"red\", bins = 200)+\n  geom_histogram(aes(terna_price), alpha = 0.2, colour = \"lightblue\", bins = 200)+\n  theme_bw()+\n  ggtitle(label = \"APG vs Terna (distribution)\")\n\n\n\n\n\nVery surprising. I have no idea why the distribution is so different.\nUnder normal circumstances/normal price levels for imbalance prices - APG seems to have a much smoother distribution. Terna presents more of a multimodal distribution, peaking around zero and two more peaks - probably values concentrate around the MGP/day-ahead price."
  },
  {
    "objectID": "posts/out_of_balance/index.html#picasso-data",
    "href": "posts/out_of_balance/index.html#picasso-data",
    "title": "Out of balance",
    "section": "Picasso data",
    "text": "Picasso data\nFrom the transnetbw.de website we can download price and volume data for the PICASSO platform. The problem working with Picasso data is the very granular nature of the datasets, prices and volumes are published in 4 seconds intervals. In order to work with the data it is necessary to aggregate to quarthourly granularity (to see what approach is used for aggregation see the code section).\n\n\nCode\nprices <- arrow::open_dataset(\"./data/picasso/prices\") %>% \n  select(dt, terna_pos, terna_neg, apg_pos, apg_neg, qo)\n\nvolumes <- arrow::open_dataset(\"./data/picasso/volumes\") %>% \n  select(dt, terna, apg, qo)\n\n\ndata <- prices %>% \n  left_join(volumes, by = c(\"dt\", \"qo\")) %>% \n  collect()\n\n\n# i made a mistake while downloading \n# i should have parsed the single files to convert to numeric\n# now i have to do it manually\n\n## raw picasso: splice volumes in order to avoid netting of volumes (negative and positive)\npicasso_df <- data %>% \n  mutate(\n    terna_pos = as.numeric(terna_pos), \n    terna_neg = as.numeric(terna_neg), \n    terna = as.numeric(terna),\n    apg = as.numeric(apg),\n    apg_pos = as.numeric(apg_pos),\n    apg_neg = as.numeric(apg_neg)\n    ) %>% \n  mutate(\n    terna_pos_vol = if_else(terna > 0, terna, NA),\n    terna_neg_vol = if_else(terna < 0, terna, NA),\n    apg_pos_vol = if_else(apg > 0, apg, NA),\n    apg_neg_vol = if_else(apg < 0, apg, NA)\n  )\n\n## calculate volume weighted prices\n\n\npicasso_df_aggr <- picasso_df %>% \n  group_by(qo) %>% \n  summarise(\n    terna_vw_price_neg = sum(terna_pos_vol * terna_neg, na.rm = TRUE)/sum(terna_pos_vol, na.rm = TRUE),\n    terna_vw_price_pos = sum(terna_neg_vol * terna_pos, na.rm = TRUE)/sum(terna_neg_vol, na.rm = TRUE),\n    apg_vw_price_pos   = sum(apg_pos_vol * terna_neg, na.rm = TRUE)/sum(apg_pos_vol, na.rm = TRUE),\n    apg_vw_price_neg   = sum(apg_neg_vol * terna_pos, na.rm = TRUE)/sum(apg_neg_vol, na.rm = TRUE),\n    ## calculate total volume called for both zones\n    terna_total_pos_called = sum(terna_pos, na.rm  = TRUE) / n(),\n    terna_total_neg_called = sum(terna_neg, na.rm = TRUE) / n(),\n    apg_total_pos_called   = sum(apg_pos, na.rm = TRUE) / n(),\n    apg_total_neg_called   = sum(apg_neg, na.rm = TRUE) / n()\n  ) %>% \n  ungroup() %>% \n  left_join(combined_prices, by = c(\"qo\" = \"df\"))\n\n\n\n\nCode\n# picasso_df_aggr - complete dataset - picasso and imbalanceprices\n# first let's analyse terna and establish whether picasso prices influence imbalance prices\n\n# prepare terna data\n\nterna <- picasso_df_aggr %>% select(qo, starts_with(\"terna\"))\n\nterna_imbalance_volues <- arrow::read_parquet(file = \"./data/terna_imbalance_volumes.parquet\") %>% \n  select(reference_date, imbalance = zonal_aggregate_unbalance_MWh)\n\nterna_splits_long_short <- terna %>% \n  left_join(terna_imbalance_volues, by = c(\"qo\" = \"reference_date\")) %>% \n  mutate(imbalance_bin = if_else(imbalance > 0, \"long\", \"short\")) %>% \n  split(.$imbalance_bin)\n\n\n\nTerna\n\nPrices\nFirst I investigate the relationship between realized Picasso prices and imbalance prices for each imbalance sign. In the following plot we look at quarter hours with a positive control area imbalance. Indeed there is a strong link between Picasso prices and imbalance prices in the control area.\n\n\nCode\n# we can see indeed the relationship of volume weighted picasso prices\n# and imbalance prices\n\nterna_splits_long_short$long %>% \n  ggplot(aes(terna_price, terna_vw_price_neg))+\n  geom_point(alpha = 0.3) +\n  theme_bw() +\n  ggtitle(\"Volume weighted Picasso prices vs Imbalance Prices (Postive imbalance)\")\n\n\n\n\n\nEven looking at the less extreme values we see a strong correlation between Picasso prices and imbalance prices.\n\n\nCode\nterna_splits_long_short$long %>% \n  filter(terna_price > -100) %>% \n  filter(terna_vw_price_neg > -100) %>% \n  ggplot(aes(terna_price, terna_vw_price_neg))+\n  geom_point(alpha = 0.1) +\n  geom_smooth(method = \"lm\")+\n  theme_bw() +\n  ggtitle(\"Volume weighted Picasso prices vs Imbalance Prices (zoomed in)\")\n\n\n\n\n\nThe same strong link is visible filtering for hours with negative control area imbalance.\n\n\nCode\n# the same as above\nterna_splits_long_short$short %>% \n  ggplot(aes(terna_price, terna_vw_price_pos))+\n  geom_point(alpha = 0.3)+\n  theme_bw()+\n  ggtitle(\"Volume weighted Picasso prices vs Imbalance Prices (negative imbalance)\")\n\n\n\n\n\n\n\nCode\nterna_splits_long_short$short %>% \n  filter(terna_price < 400 & terna_vw_price_pos < 500) %>% \n  ggplot(aes(terna_price, terna_vw_price_pos))+\n  geom_point(alpha = 0.1)+\n  geom_smooth(method = \"lm\")+\n  theme_bw() +\n  ggtitle(\"Volume weighted Picasso prices vs Imbalance Prices (zoomed in)\")\n\n\n\n\n\nThe relationship between volume weighted prices and imbalance prices is more complex in short hours. While there exists a relationship for some quarter hours, in others the imbalance price is completely detached, a Picasso price of 0 leads to a non zero imbalance price in the control area (all the points concentrating on the 0 value of the x axis).\n\n\nVolumes\nWe can observe that the price for secondary reserve on the Picasso platform is highly dependent on the volume requested.\n\n\nCode\nterna_splits_long_short$long %>% \n  ggplot(aes(terna_vw_price_neg, terna_total_neg_called))+\n  geom_point(alpha = 0.4)+\n  theme_bw()+\n  ggtitle(\"Total negative sec. reserve called vs price for sec. reserve\")\n\n\n\n\n\nLet’s zoom in to see the concentration of points in the top right corner.\n\n\nCode\nterna_splits_long_short$long %>%\n  filter(terna_total_neg_called >= -300 & terna_vw_price_neg >= -300) %>% \n  ggplot(aes(terna_vw_price_neg, terna_total_neg_called))+\n  geom_point(alpha = 0.2)+\n  theme_bw()+\n  ggtitle(\"Total negative sec. reserve called vs price for sec. reserve\")\n\n\n\n\n\n\n\nCode\nterna_splits_long_short$short %>% \n  ggplot(aes(terna_vw_price_pos, terna_total_pos_called))+\n  geom_point(alpha = 0.4)+\n  theme_bw()+\n  ggtitle(\"Total positive sec. reserve called vs price for sec. reserve\")\n\n\n\n\n\nThe same strong link between called volumes and prices is true for upwards reserve.\n\n\nCode\nterna_splits_long_short$short %>%\n  filter(terna_vw_price_pos < 1000) %>% \n  filter(terna_total_pos_called < 1000) %>% \n  ggplot(aes(terna_vw_price_pos, terna_total_pos_called))+\n  geom_point(alpha = 0.4)+\n  theme_bw()+\n  ggtitle(\"Total positive sec. reserve called vs price for sec. reserve\")\n\n\n\n\n\nLike in the case of negative aFRR called also in case of calling positive aFRR there is almost a linear relationship between volumes and prices, with the exception of quite some quarter hours, that have a price of 0 while Terna is calling volumes from the Picasso platform.\n\n\nLink to Imbalance prices in the control area NORD Terna\n\n\nCode\nterna_splits_long_short$long %>% \n  select(terna_total_neg_called, terna_price, imbalance, terna_vw_price_neg) %>% \n  GGally::ggpairs(alpha = 0.3)+\n  theme_bw()\n\n\n\n\n\n\n\nCode\nterna_splits_long_short$short %>% \n  select(terna_total_pos_called, terna_price, imbalance, terna_vw_price_pos) %>% \n  GGally::ggpairs(alpha = 0.3)+\n  theme_bw()\n\n\n\n\n\nBoth graphs show the strong link between imbalance prices and volume weighted picasso prices. However, we should keep in mind that it would be challenging working with this predictor, since picasso is not called upon in all quarter hours.\n\n\nCode\nterna_splits_long_short$long %>% \n  mutate(\n    price_published = if_else(is.na(terna_vw_price_neg), 0, 1),\n    volume_published = if_else(is.na(terna_total_neg_called), 0, 1)\n  ) %>% \n  summarise(\n    prices_published = sum(price_published)/n()\n  ) %>% \n  mutate(across(everything(),~round(., 2)))\n\n\n# A tibble: 1 × 1\n  prices_published\n             <dbl>\n1             0.36\n\n\nPrice data is only available for roughly a third of quarter hours - at least in the period subject to this analyiss.\n\n\n\nAPG\n\nPrices\n\n\nCode\n# prepare terna data\n\napg <- picasso_df_aggr %>% select(qo, starts_with(\"apg\"))\n\napg_imbalance_volumes <- arrow::read_parquet(file = \"./data/apg_control_area_imbalance.parquet\") %>% \n  select(df, imbalance = cai)\n\napg_splits_long_short <- apg %>% \n  left_join(apg_imbalance_volumes, by = c(\"qo\" = \"df\")) %>% \n  mutate(imbalance_bin = if_else(imbalance > 0, \"long\", \"short\")) %>% \n  split(.$imbalance_bin)\n\n\n\n\nCode\napg_splits_long_short$long %>% \n  ggplot(aes(apg_price, apg_vw_price_neg))+\n  geom_point(alpha = 0.3) +\n  theme_bw() +\n  ggtitle(\"Volume weighted Picasso prices vs Imbalance Prices (Postive imbalance)\")\n\n\n\n\n\n\n\nCode\napg_splits_long_short$long %>% \n  filter(apg_price > -400 & apg_vw_price_neg < 700) %>% \n  ggplot(aes(apg_price, apg_vw_price_neg))+\n  geom_point(alpha = 0.3) +\n  theme_bw() +\n  ggtitle(\"Volume weighted Picasso prices vs Imbalance Prices (Postive imbalance)\")\n\n\n\n\n\n\n\nCode\napg_splits_long_short$short %>% \n  ggplot(aes(apg_price, apg_vw_price_pos))+\n  geom_point(alpha = 0.3)+\n  theme_bw()+\n  ggtitle(\"Volume weighted Picasso prices vs Imbalance Prices (negative imbalance)\")\n\n\n\n\n\n\n\nCode\napg_splits_long_short$short %>% \n  filter(apg_price < 400 & apg_price > -100) %>% \n  filter(apg_vw_price_pos < 400 & apg_vw_price_pos > 0) %>% \n  ggplot(aes(apg_price, apg_vw_price_pos))+\n  geom_point(alpha = 0.3)+\n  theme_bw()+\n  ggtitle(\"Volume weighted Picasso prices vs Imbalance Prices (negative imbalance)\")\n\n\n\n\n\nOverall the link between imbalance prices and picasso prices/volumes seems to be much much clearer in the case fo Terna. APG doesn’t present a strong and well identifiable link.\n\n\nVolumes\n\n\nCode\napg_splits_long_short$long %>% \n  ggplot(aes(apg_vw_price_neg, apg_total_neg_called))+\n  geom_point(alpha = 0.4)+\n  theme_bw()+\n  ggtitle(\"Total negative sec. reserve called vs price for sec. reserve\")"
  },
  {
    "objectID": "posts/out_of_balance/index.html#exploring-the-volumetric-link-between-apg-and-terna",
    "href": "posts/out_of_balance/index.html#exploring-the-volumetric-link-between-apg-and-terna",
    "title": "Out of balance",
    "section": "Exploring the volumetric link between APG and Terna",
    "text": "Exploring the volumetric link between APG and Terna\nHere we can compare volumes - we detect the accession of Terna to the platfrom and also a pause in their participation.\n\n\nCode\npicasso_vol_data<- picasso_df %>% select(dt, contains(\"vol\")) %>% \n  mutate(across(everything(), ~replace_na(., 0))) %>% \n  transmute(dt = dt, terna_vol = terna_pos_vol + terna_neg_vol, apg_vol = apg_pos_vol + apg_neg_vol) %>% \n  pivot_longer(-dt) %>% \n  drop_na() %>% \n  group_by(name) %>% \n  summarise_by_time(\n    .date_var = dt, .by = \"15 min\", value = mean(value)\n  ) %>% \n  ungroup() \n\npicasso_vol_data %>% \n  timetk::plot_time_series(dt, value, name, .smooth = FALSE, .title = \"Volumes called by each TSO\")\n\n\n\n\n\n\nThere seems to be a somewhat negative relationship between volumes. The two TSOs mirroring their volume calls on PICASSO.\n\n\nCode\npicasso_vol_data %>% \n  pivot_wider(names_from = name, values_from = value) %>% \n  filter(dt >= \"2023-10-25\") %>% \n  ggplot(aes(terna_vol, apg_vol))+\n  geom_point(alpha = 0.3)+\n  theme_bw()+\n  ggtitle(label = \"Volumes since end of October\")\n\n\n\n\n\n\nExample 26th of August 2023\nAn extreme day in terms of imbalance prices in Austria. We see too that volumes do somewhat correlate on this day. In particular there are 3 phases where Terna and APG call upon a similar level of volumes. For some periods there is a clear relationship between volumes and the imbalance price in Austria, however the very high imbalance prices from 8:00 to 8:30 fall out of this pattern.\n\n\nCode\nplot_volumes  <- picasso_df %>% \n  filter(date(qo) == \"2023-08-26\") %>% \n  select(dt, contains(\"vol\")) %>% \n  pivot_longer(-dt) %>% \n  timetk::plot_time_series(\n    dt, value, name, .smooth = FALSE,\n    .title = \"4s granularity - volumes data + imbalance prices /10\",\n    .interactive = FALSE\n  )\n\nimb_price <- picasso_df_aggr %>% \n  select(qo, apg_price) %>% \n  filter(date(qo) == \"2023-08-26\") %>% \n  mutate(apg_price = apg_price/10)\n\nplot_vol_price <- plot_volumes + \n  geom_point(imb_price, mapping = aes(qo, apg_price))\n\nplotly::ggplotly(plot_vol_price)"
  },
  {
    "objectID": "posts/optimisation/index.html",
    "href": "posts/optimisation/index.html",
    "title": "Optimisation",
    "section": "",
    "text": "First we download some price data, here I use Austrian price data for the month of November 2023. The main idea and structure of the code comes from the book “Virtual Power Plants and Electricity Markets” from Springer. Various power plant types are being optimised in the book, however it is not trivial to translate the code therein (written in GAMS which is not open source) to julia.\nIn this example we work with a thermal plant which has several parameters:\n\nprices: a vector of prices we feed to the model\nvariable cost: in our example we work with fixed variable cost, in a future project we might want to look at having a vector of variable costs, some kind of conversion of ttf, eua and powerplant efficiency to mwh.\nstartup_cost: cost incurred by the plant when it is switched on\nshutdown_cost: cost of shutting down\nmin_tech: minimal non zero production possibile (we don’t want the powerplant to produce tiny amounts of power\nfor many powerplants this is not even possible, in addition we don’t want the powerplant to artificially avoid startup or shutdown costs by producing tiny amounts of power)\nramping_up: possible ramping upwards\nramping_down: possible down ramping\nstartup_ramping: possible ramping when switching on (this should not be smaller than min_tech)\nshutdown_ramping: possible ramping when shutting down (also shouldn’t be smaller than min_tech)\n\nCollapse to see function we are running\n\n\nCode\n\n#| eval: false\n\nusing GLPK\nusing JuMP\nusing CSV\nusing DataFrames\n\nfunction thermalplant(prices, variable_cost, startup_cost, shutdown_cost, min_tech, ramping_up, ramping_down, startup_ramping, shutdown_ramping)\n\n    n = length(prices)\n\n    model = Model(GLPK.Optimizer)\n\n    @variable(model, running[1:n], Bin)\n    @variable(model, p[1:n] >= 0)\n\n    # seems to work\n    for i in 1:n\n        @constraint(model, p[i] <= capacity * running[i]) \n        @constraint(model, p[i] >= min_tech * running[i])\n    end\n\n    @variable(model, startup[1:n], Bin)\n    @variable(model, shutdown[1:n], Bin)\n\n    for i in 2:n\n        # 0 if running; -1 if shutdown, 1 if swich on\n        @constraint(model, running[i] - running[i - 1] == startup[i] - shutdown[i])\n        @constraint(model, startup[i] + shutdown[i] <= 1)\n\n        @constraint(model, p[i] - p[i - 1] <= (ramping_up * running[i - 1]) + (startup_ramping * startup[i]))\n        @constraint(model, p[i - 1] - p[i] <= (ramping_down * running[i - 1]) + (shutdown_ramping * shutdown[i]))\n\n    end\n\n    @objective(\n        model, Max,\n        sum(\n            (prices[i] * p[i]) - (variable_cost * p[i]) - (startup_cost * startup[i]) - (shutdown_cost * shutdown[i])\n            for i in 1:n\n        )\n    )\n\n    optimize!(model)\n\n    return value.(p)\n\nend\n\n\nthermalplant (generic function with 1 method)\n\n\nCode\n\n\n#capacity = 10\n#variable_cost = 130\n#startup_cost = 4000\n#shutdown_cost = 3000\n#min_tech      = 3\n#ramping_up = 0.3\n#ramping_down = 0.4\n#startup_ramping = 3.3\n#shutdown_ramping = 3.4\n#\n#\n#prices_df = CSV.read(\"./data/aus15minprices.csv\", DataFrame)\n#prices_df = rename!(prices_df, [:date, :price])\n#\n#plant1 = thermalplant(\n#  prices_df.price,\n#  130,\n#  4000,\n#  3000,\n#  3,\n#  1,\n#  1,\n#  4,\n#  4\n#)\n#\n\n\nWe create some possible values for the power plant and run the simulation, however we’re going to call the function via python, to make it easier\n\n\nCode\nimport julia\nfrom julia import Main\nimport os\nimport pandas as pd\n\nos.getcwd()\nMain.include(\"termalplant.jl\")\n\nprices = pd.read_csv(\"./posts/optimisation/data/aus15minprices.csv\")\nprices.columns = ['date', 'price']\n\n\ncapacity = 10\nvariable_cost = 90\nstartup_cost = 4000\nshutdown_cost = 3000\nmin_tech      = 3\nramping_up = 0.3\nramping_down = 0.4\nstartup_ramping = 3.3\nshutdown_ramping = 3.4\n\nprice_list = prices['price'].tolist()\n\nsimul1 = Main.thermalplant(\n    price_list,\n    capacity,\n    variable_cost,\n    startup_cost,\n    shutdown_cost,\n    min_tech,\n    ramping_up,\n    ramping_down,\n    startup_ramping,\n    shutdown_ramping\n    )\n\nprices[\"simul1\"] = simu1\n\n# lets keep all as it was and just alter the min tech downwards to 2 MW\n\nsimul2 = Main.thermalplant(\n    price_list,\n    10, #capacity\n    90, #variable_cost\n    4000, #startup_cost\n    3000, #shutdown_cost\n    2, #min_tech\n    0.3, #ramping_up\n    0.4, #ramping_down\n    3.3, #startup_ramping \n    3.4, #shutdown_ramping\n    )\n\nprices[\"simul2\"] = simul2\n\n# lets have much higher ramping\n\nsimul3 = Main.thermalplant(\n    price_list,\n    10, #capacity\n    90, #variable_cost\n    4000, #startup_cost\n    3000, #shutdown_cost\n    3, #min_tech\n    2, #ramping_up\n    2, #ramping_down\n    3.3, #startup_ramping \n    3.4, #shutdown_ramping\n    )\n\nprices[\"simul3\"] = simul3\n\nprices.to_csv(\"./data/simuls.csv\")\n\n\n\n\nAs specified in the code above we have 3 simulations:\n\nsimul1 is our baseline,\nsimul2 has a lower min_tech value\nsimul3 has the ability to ramp more\n\nLet’s visualise the optimisation results.\n\n\nCode\nlibrary(tidyverse)\nlibrary(timetk)\n\ndata <- read_csv(\"./data/simuls.csv\") %>% \n  select(-1)\n\n\ndata %>%\n  pivot_longer(-date) %>% \n  mutate(type = if_else(name == \"price\", \"price\", \"simul\")) %>% \n  group_by(type) %>% \n  timetk::plot_time_series(\n  date, value, name, .smooth = FALSE, .title = \"Quarthourly Austrian day ahead prices (ENTSO-E)\"\n)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "powerpulse",
    "section": "",
    "text": "Cold as ICE\n\n\n\n\n\n\n\nfutures\n\n\n\n\n\n\n\n\n\n\n\nDec 10, 2023\n\n\nJakob Prossliner\n\n\n\n\n\n\n  \n\n\n\n\nOut of balance\n\n\n\n\n\n\n\nimbalance\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 25, 2023\n\n\nJakob Prossliner\n\n\n\n\n\n\n  \n\n\n\n\nOptimisation\n\n\n\n\n\n\n\noptimisation\n\n\n\n\n\n\n\n\n\n\n\nNov 25, 2023\n\n\nJakob Prossliner\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  }
]